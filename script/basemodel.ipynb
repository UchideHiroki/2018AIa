{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision tqdm annoy gensim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy, deepcopy\n",
    "from random import sample\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#from gensim.similarities.index import AnnoyIndexer\n",
    "from scipy.stats import spearmanr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from multiprocessing import Pool\n",
    "import unicodedata\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 266 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    \n",
    "# 大文字を全部小文字にする\n",
    "# 無駄な空白や文字じゃないやつを全部消す\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\"\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\"\", s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 65.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# あらかじめ入力する単語を綺麗にしておく\n",
    "# 全て小文字にして、a-z以外の単語を取り除く\n",
    "normalized_words = set([normalizeString(word) for word in embedding.vocab.keys()]) & embedding.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(normalized_words) * 0.8)\n",
    "n_validate = int(len(normalized_words) * 0.1)\n",
    "n_test = len(normalized_words) - n_train - n_validate\n",
    "\n",
    "all_words = list(normalized_words)\n",
    "train_words = set(sample(all_words, n_train))\n",
    "validate_words = set(sample(list(set(all_words) - train_words), n_validate))\n",
    "test_words = normalized_words - train_words - validate_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5647, 705, 707, 7059)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train, n_validate, n_test, len(normalized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルパラメータの設定\n",
    "all_letters = string.ascii_lowercase\n",
    "n_letters = len(all_letters)\n",
    "input_size = n_letters\n",
    "        \n",
    "def letter2tensor(letter):\n",
    "    return all_letters.index(letter)\n",
    "\n",
    "def letter2onehot(letter):\n",
    "    tensor = torch.zeros(1, n_letters, device=device)\n",
    "    tensor[0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def word2input_tensors(word):\n",
    "    return torch.tensor([letter2tensor(letter) for letter in word]) * 1.0\n",
    "\n",
    "def word2input_one_hot(word):\n",
    "     return torch.cat([letter2onehot(l) for l in word], dim=0)\n",
    "    \n",
    "def word2target_tensor(word):\n",
    "    return torch.from_numpy(embedding[word]).view(1, -1).to(device)\n",
    "\n",
    "#calc the time\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder(basemodel)\n",
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EncoderGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, 1)\n",
    "        self.affin = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        # input is (the len of alfabet inwords, the num of type = 26, hidden = 100)\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded.view(-1, 1, self.hidden_size)   \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # output is hiddensize * lengthofwords        \n",
    "        output_splitter_prob =  F.softmax(torch.sum(output, dim = 2).view(output.size(0)))\n",
    "        output_weighted = output.view(output.size(0), self.hidden_size) * output_splitter_prob.view(output.size(0),1)\n",
    "        # hr (lenof word * hidden)\n",
    "        sum_hr = torch.sum(output_weighted, dim = 0)\n",
    "        output = self.affin(sum_hr.view(self.hidden_size))        \n",
    "        return output, output_splitter_prob\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder(bidirectional)\n",
    "class EncoderGRU_second(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EncoderGRU_second, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, 1, dropout = 0.3)\n",
    "        \n",
    "        # addtional NN for the outputs to get their weights\n",
    "        \n",
    "        self.affin_prob_pre = nn.Linear(self.hidden_size, 10)\n",
    "        self.affin_activate = nn.LeakyReLU()\n",
    "        self.affin_prob_suf = nn.Linear(10, 1)\n",
    "        \n",
    "        #last affine\n",
    "        self.affin = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        #dynamical net: initialize\n",
    "        self.output_affin_list = []\n",
    "        \n",
    "        \n",
    "        # input is (the len of alfabet inwords, the num of type = 26, hidden = 100)\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded.view(-1, 1, self.hidden_size)   \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        \n",
    "        # output is hiddensize * length of words\n",
    "        #torch_sum = torch.sum(output, dim = 2).view(output.size(0))\n",
    "        \n",
    "        #this time, try NN as the weight of output\n",
    "        output_pre_affin = self.affin_prob_pre(output.view(-1, self.hidden_size))\n",
    "        output_activate = self.affin_activate(output_pre_affin)\n",
    "        torch_sum = self.affin_prob_suf(output_activate)\n",
    "        \n",
    "        \n",
    "        output_splitter_prob =  F.softmax(torch_sum.view(torch_sum.size(0)))\n",
    "        \n",
    "        output_weighted = output.view(output.size(0), self.hidden_size) * output_splitter_prob.view(output.size(0),1)\n",
    "        \n",
    "        \n",
    "        # hr (lenof word * hidden)\n",
    "        sum_hr = torch.sum(output_weighted, dim = 0)\n",
    "        output = self.affin(sum_hr.view(self.hidden_size)) \n",
    "        \n",
    "        return output, output_splitter_prob\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 2 means bidirectional\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU_third(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EncoderGRU_third, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
    "        self.gru = nn.LSTM(self.hidden_size, self.hidden_size, 1, dropout = 0.3)\n",
    "        \n",
    "        # addtional NN for the outputs to get their weights\n",
    "        \n",
    "        self.affin_prob_pre = nn.Linear(self.hidden_size, 1)\n",
    "        self.threshold = nn.Threshold(0.20, 0)\n",
    "        #self.affin_activate = nn.Hardtanh()\n",
    "        #self.affin_prob_suf = nn.Linear(10, 1)\n",
    "        \n",
    "        #last affine\n",
    "        self.affin = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        #dynamical net: initialize\n",
    "        self.output_affin_list = []\n",
    "        \n",
    "        \n",
    "        # input is (the len of alfabet inwords, the num of type = 26, hidden = 100)\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded.view(-1, 1, self.hidden_size)   \n",
    "        output, hidden = self.gru(output, (hidden, cell))\n",
    "        \n",
    "        \n",
    "        # output is hiddensize * length of words\n",
    "        torch_sum = torch.sum(output, dim = 2).view(output.size(0))\n",
    "        #this time, try NN as the weight of output\n",
    "        \n",
    "        \n",
    "        #output_pre_affin = self.affin_prob_pre(output.view(-1, self.hidden_size))\n",
    "        #torch_sum = output_pre_affin\n",
    "        \n",
    "        #output_activate = self.affin_activate(output_pre_affin)\n",
    "        #torch_sum = self.affin_prob_suf(output_activate)\n",
    "        # tanh -> relu\n",
    "        \n",
    "        \n",
    "        output_splitter_prob = F.softmax(torch_sum.view(torch_sum.size(0)))\n",
    "        output_splitter_prob = self.threshold(F.relu(output_splitter_prob))\n",
    "        output_weighted = output.view(output.size(0), self.hidden_size) * output_splitter_prob.view(output.size(0),1)\n",
    "        \n",
    "        \n",
    "        # hr (len of word * hidden)\n",
    "        sum_hr = torch.sum(output_weighted, dim = 0)\n",
    "        output = self.affin(sum_hr.view(self.hidden_size)) \n",
    "        \n",
    "        return output, output_splitter_prob\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 2 means bidirectional\n",
    "        #return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        return(torch.zeros(1,1, self.hidden_size, device = device), torch.zeros(1,1,self.hidden_size, device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGRU_forth(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EncoderGRU_forth, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.gru = nn.LSTM(self.input_size, self.hidden_size, 1, dropout = 0.3)\n",
    "        \n",
    "        # addtional NN for the outputs to get their weights\n",
    "        \n",
    "        self.affin_prob_pre = nn.Linear(self.hidden_size, 1)\n",
    "        self.threshold = nn.Threshold(0.20, 0)\n",
    "        #self.affin_activate = nn.Hardtanh()\n",
    "        #self.affin_prob_suf = nn.Linear(10, 1)\n",
    "        \n",
    "        #last affine\n",
    "        self.affin = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input is (the len of alfabet inwords, the num of type = 26, hidden = 100)\n",
    "        output, hidden = self.gru(input.view(input.size(0),1,-1) , (hidden, cell))\n",
    "        \n",
    "        \n",
    "        # output is hiddensize * length of words\n",
    "        torch_sum = torch.sum(output, dim = 2).view(output.size(0))\n",
    "        #this time, try NN as the weight of output\n",
    "        \n",
    "        \n",
    "        #output_pre_affin = self.affin_prob_pre(output.view(-1, self.hidden_size))\n",
    "        #torch_sum = output_pre_affin\n",
    "        \n",
    "        #output_activate = self.affin_activate(output_pre_affin)\n",
    "        #torch_sum = self.affin_prob_suf(output_activate)\n",
    "        # tanh -> relu\n",
    "        \n",
    "        \n",
    "        output_splitter_prob = F.softmax(torch_sum.view(torch_sum.size(0)))\n",
    "        output_splitter_prob = self.threshold(F.relu(output_splitter_prob))\n",
    "        output_weighted = output.view(output.size(0), self.hidden_size) * output_splitter_prob.view(output.size(0),1)\n",
    "        \n",
    "        \n",
    "        # hr (len of word * hidden)\n",
    "        sum_hr = torch.sum(output_weighted, dim = 0)\n",
    "        output = self.affin(sum_hr.view(self.hidden_size)) \n",
    "        \n",
    "        return output, output_splitter_prob\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 2 means bidirectional\n",
    "        #return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        return(torch.zeros(1,1, self.hidden_size, device = device), torch.zeros(1,1,self.hidden_size, device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, encoder_optimizer, criterion):\n",
    "    encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_output, splitter_prob = encoder(input_tensor, encoder_hidden,encoder_cell)\n",
    "    loss = criterion(encoder_output, target_tensor.view(300))\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, all_words, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adagrad(encoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # all_word\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    for epoch in range(n_iters):\n",
    "        for iter in range(len(all_words)):\n",
    "            input_tensor = torch.tensor(word2input_one_hot(all_words[iter]),device=device)\n",
    "            target_tensor = word2target_tensor(all_words[iter])\n",
    "        \n",
    "            loss = train(input_tensor, target_tensor, encoder, encoder_optimizer, criterion)\n",
    "        \n",
    "        \n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "            if iter % print_every == 0:\n",
    "                print_loss_avg = print_loss_total #/ print_every\n",
    "                print_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, (iter + 1) / n_iters), iter, (iter+1) / n_iters * 100, print_loss_avg))\n",
    "\n",
    "            if iter % plot_every == 0:\n",
    "                plot_loss_avg = plot_loss_total / plot_every\n",
    "                plot_losses.append(plot_loss_avg)\n",
    "                plot_loss_total = 0\n",
    "                \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akihiro\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "C:\\Users\\akihiro\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (- 0m 0s) (0 33%) 0.0147\n",
      "0m 5s (- -1m 54s) (100 3366%) 1.4353\n",
      "0m 10s (- -1m 49s) (200 6700%) 1.2904\n",
      "0m 15s (- -1m 44s) (300 10033%) 1.4368\n",
      "0m 20s (- -1m 39s) (400 13366%) 1.4301\n",
      "0m 25s (- -1m 34s) (500 16700%) 1.4521\n",
      "0m 30s (- -1m 29s) (600 20033%) 1.3561\n",
      "0m 36s (- -1m 24s) (700 23366%) 1.4026\n",
      "0m 41s (- -1m 18s) (800 26700%) 1.3943\n",
      "0m 46s (- -1m 14s) (900 30033%) 1.3852\n",
      "0m 50s (- -1m 9s) (1000 33366%) 1.3245\n",
      "0m 55s (- -1m 4s) (1100 36700%) 1.4115\n",
      "1m 1s (- -2m 58s) (1200 40033%) 1.3847\n",
      "1m 7s (- -2m 53s) (1300 43366%) 1.4446\n",
      "1m 12s (- -2m 47s) (1400 46700%) 1.4232\n",
      "1m 17s (- -2m 42s) (1500 50033%) 1.3575\n",
      "1m 22s (- -2m 37s) (1600 53366%) 1.3567\n",
      "1m 28s (- -2m 32s) (1700 56700%) 1.2804\n",
      "1m 33s (- -2m 26s) (1800 60033%) 1.4218\n",
      "1m 38s (- -2m 21s) (1900 63366%) 1.5293\n",
      "1m 43s (- -2m 16s) (2000 66700%) 1.3525\n",
      "1m 49s (- -2m 11s) (2100 70033%) 1.3566\n",
      "1m 54s (- -2m 5s) (2200 73366%) 1.4156\n",
      "1m 59s (- -2m 0s) (2300 76700%) 1.3256\n",
      "2m 5s (- -3m 55s) (2400 80033%) 1.3941\n",
      "2m 11s (- -3m 49s) (2500 83366%) 1.3218\n",
      "2m 16s (- -3m 43s) (2600 86700%) 1.3730\n",
      "2m 21s (- -3m 38s) (2700 90033%) 1.3654\n",
      "2m 27s (- -3m 32s) (2800 93366%) 1.4082\n",
      "2m 33s (- -3m 27s) (2900 96700%) 1.3731\n",
      "2m 38s (- -3m 21s) (3000 100033%) 1.2516\n",
      "2m 43s (- -3m 16s) (3100 103366%) 1.3082\n",
      "2m 48s (- -3m 11s) (3200 106700%) 1.3219\n",
      "2m 54s (- -3m 5s) (3300 110033%) 1.4542\n",
      "3m 1s (- -4m 58s) (3400 113366%) 1.4642\n",
      "3m 7s (- -4m 53s) (3500 116700%) 1.3038\n",
      "3m 12s (- -4m 48s) (3600 120033%) 1.3433\n",
      "3m 17s (- -4m 42s) (3700 123366%) 1.4563\n",
      "3m 23s (- -4m 36s) (3800 126700%) 1.3099\n",
      "3m 29s (- -4m 30s) (3900 130033%) 1.2788\n",
      "3m 34s (- -4m 25s) (4000 133366%) 1.3949\n",
      "3m 40s (- -4m 20s) (4100 136700%) 1.2915\n",
      "3m 46s (- -4m 13s) (4200 140033%) 1.4178\n",
      "3m 51s (- -4m 8s) (4300 143366%) 1.3868\n",
      "3m 56s (- -4m 3s) (4400 146700%) 1.3794\n",
      "4m 2s (- -5m 57s) (4500 150033%) 1.3393\n",
      "4m 7s (- -5m 52s) (4600 153366%) 1.3605\n",
      "4m 13s (- -5m 47s) (4700 156700%) 1.3943\n",
      "4m 20s (- -5m 39s) (4800 160033%) 1.3803\n",
      "4m 26s (- -5m 33s) (4900 163366%) 1.3609\n",
      "4m 32s (- -5m 27s) (5000 166700%) 1.3926\n",
      "4m 38s (- -5m 21s) (5100 170033%) 1.3660\n",
      "4m 44s (- -5m 15s) (5200 173366%) 1.4253\n",
      "4m 50s (- -5m 9s) (5300 176700%) 1.3972\n",
      "4m 56s (- -5m 3s) (5400 180033%) 1.4217\n",
      "5m 1s (- -6m 58s) (5500 183366%) 1.4144\n",
      "5m 7s (- -6m 52s) (5600 186700%) 1.3356\n",
      "5m 13s (- -6m 46s) (5700 190033%) 1.3287\n",
      "5m 19s (- -6m 40s) (5800 193366%) 1.3188\n",
      "5m 24s (- -6m 35s) (5900 196700%) 1.4240\n",
      "5m 30s (- -6m 29s) (6000 200033%) 1.3796\n",
      "5m 36s (- -6m 23s) (6100 203366%) 1.3692\n",
      "5m 42s (- -6m 17s) (6200 206700%) 1.3196\n",
      "5m 48s (- -6m 11s) (6300 210033%) 1.4304\n",
      "5m 55s (- -6m 4s) (6400 213366%) 1.3903\n",
      "6m 1s (- -7m 58s) (6500 216700%) 1.3902\n",
      "6m 8s (- -7m 51s) (6600 220033%) 1.4301\n",
      "6m 14s (- -7m 45s) (6700 223366%) 1.3522\n",
      "6m 19s (- -7m 40s) (6800 226700%) 1.3769\n",
      "6m 25s (- -7m 34s) (6900 230033%) 1.2678\n",
      "6m 30s (- -7m 29s) (7000 233366%) 1.3685\n",
      "6m 34s (- 13m 8s) (0 33%) 0.7718\n",
      "6m 39s (- -7m 32s) (100 3366%) 1.3747\n",
      "6m 45s (- -7m 20s) (200 6700%) 1.2647\n",
      "6m 50s (- -7m 13s) (300 10033%) 1.4147\n",
      "6m 55s (- -7m 7s) (400 13366%) 1.4064\n",
      "7m 0s (- -7m 1s) (500 16700%) 1.4342\n",
      "7m 5s (- -8m 56s) (600 20033%) 1.3377\n",
      "7m 11s (- -8m 50s) (700 23366%) 1.3849\n",
      "7m 16s (- -8m 45s) (800 26700%) 1.3806\n",
      "7m 21s (- -8m 40s) (900 30033%) 1.3758\n",
      "7m 25s (- -8m 35s) (1000 33366%) 1.3142\n",
      "7m 30s (- -8m 30s) (1100 36700%) 1.3977\n",
      "7m 36s (- -8m 24s) (1200 40033%) 1.3726\n",
      "7m 41s (- -8m 19s) (1300 43366%) 1.4313\n",
      "7m 46s (- -8m 14s) (1400 46700%) 1.4122\n",
      "7m 51s (- -8m 9s) (1500 50033%) 1.3488\n",
      "7m 56s (- -8m 4s) (1600 53366%) 1.3486\n",
      "8m 2s (- -9m 58s) (1700 56700%) 1.2720\n",
      "8m 7s (- -9m 53s) (1800 60033%) 1.4124\n",
      "8m 12s (- -9m 47s) (1900 63366%) 1.5193\n",
      "8m 18s (- -9m 42s) (2000 66700%) 1.3437\n",
      "8m 25s (- -9m 35s) (2100 70033%) 1.3448\n",
      "8m 31s (- -9m 29s) (2200 73366%) 1.4074\n",
      "8m 36s (- -9m 23s) (2300 76700%) 1.3176\n",
      "8m 42s (- -9m 18s) (2400 80033%) 1.3870\n",
      "8m 47s (- -9m 13s) (2500 83366%) 1.3143\n",
      "8m 52s (- -9m 8s) (2600 86700%) 1.3677\n",
      "8m 57s (- -9m 2s) (2700 90033%) 1.3581\n",
      "9m 2s (- -10m 57s) (2800 93366%) 1.4013\n",
      "9m 7s (- -10m 52s) (2900 96700%) 1.3667\n",
      "9m 13s (- -10m 47s) (3000 100033%) 1.2445\n",
      "9m 18s (- -10m 42s) (3100 103366%) 1.3041\n",
      "9m 23s (- -10m 36s) (3200 106700%) 1.3166\n",
      "9m 29s (- -10m 31s) (3300 110033%) 1.4484\n",
      "9m 34s (- -10m 25s) (3400 113366%) 1.4580\n",
      "9m 40s (- -10m 20s) (3500 116700%) 1.2969\n",
      "9m 45s (- -10m 15s) (3600 120033%) 1.3376\n",
      "9m 50s (- -10m 9s) (3700 123366%) 1.4513\n",
      "9m 55s (- -10m 4s) (3800 126700%) 1.3064\n",
      "10m 1s (- -11m 58s) (3900 130033%) 1.2742\n",
      "10m 6s (- -11m 53s) (4000 133366%) 1.3886\n",
      "10m 11s (- -11m 48s) (4100 136700%) 1.2864\n",
      "10m 16s (- -11m 43s) (4200 140033%) 1.4132\n",
      "10m 22s (- -11m 38s) (4300 143366%) 1.3837\n",
      "10m 28s (- -11m 32s) (4400 146700%) 1.3750\n",
      "10m 33s (- -11m 27s) (4500 150033%) 1.3356\n",
      "10m 38s (- -11m 21s) (4600 153366%) 1.3578\n",
      "10m 44s (- -11m 15s) (4700 156700%) 1.3903\n",
      "10m 50s (- -11m 9s) (4800 160033%) 1.3752\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-225-8e3fc97135a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoderGRU_forth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_put_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-223-bfd91f82d6c2>\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(encoder, all_words, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mtarget_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2target_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-222-6dc7c7f44203>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, encoder_optimizer, criterion)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mencoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder_cell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "input_size = 26\n",
    "out_put_size = 300\n",
    "n_iters = 3\n",
    "\n",
    "\n",
    "encoder1 = EncoderGRU_forth(input_size , hidden_size, out_put_size).to(device)\n",
    "\n",
    "trainIters(encoder1, all_words, n_iters= n_iters, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_word, encoder):\n",
    "    input_tensor = torch.tensor(word2input_one_hot(input_word), dtype=torch.long, device=device)\n",
    "    encoder_hidden, encoder_cell = encoder.initHidden()\n",
    "    input_length = input_tensor.size(0)\n",
    "    output, splitter_prob = encoder(input_tensor, encoder_hidden, encoder_cell)\n",
    "    return splitter_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akihiro\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Float but got scalar type Long for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-229-6da4dc98e90f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'working'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'going'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prepare'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unlockable'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-228-5dc6d7967bb4>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(input_word, encoder)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mencoder_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minput_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplitter_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_cell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msplitter_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-221-d6fe9d239cea>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden, cell)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# input is (the len of alfabet inwords, the num of type = 26, hidden = 100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 179\u001b[1;33m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of scalar type Float but got scalar type Long for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "print(predict('working', encoder1))\n",
    "print(predict('going', encoder1))\n",
    "print(predict('prepare', encoder1))\n",
    "print(predict('unlockable', encoder1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
